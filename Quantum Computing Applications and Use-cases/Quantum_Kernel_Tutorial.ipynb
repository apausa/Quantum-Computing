{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S01DJJb-JJ26"
      },
      "source": [
        "# Quantum Kernels Tutorial: From Classial to Quantum\n",
        "Notebook for the CERN openlab Summer Student Lectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIoTDyPocUmD"
      },
      "source": [
        "# Classical kernels\n",
        "Let us dive into classical machine learning and perform classification with classical kernels."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motivation\n",
        "In many cases, our data is not linearly separable. In the case of binary classification, this means that we cannot find a hyperplane in our feature space such that it perfectly separates the two classes."
      ],
      "metadata": {
        "id": "wvbv8q0e_wPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1adrgAsTRkg9G7gk4ZxUnempq5-VwMhq1\" width=\"300\" height=\"250\" />\n"
      ],
      "metadata": {
        "id": "ZKvAhlQA_7iF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will now see how a simple kernel can help us transform this data into a new space where it is lineraly separable."
      ],
      "metadata": {
        "id": "oPgxGTUoBN-w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9ejPy1YdSy3"
      },
      "source": [
        "## Polynomial kernel\n",
        "<p>The polynomial kernel is given by:</p>\n",
        "<p><i>K(x, y)</i> = (<i>x</i> &middot; <i>y</i> + <i>c</i>)<sup><i>d</i></sup></p>\n",
        "<p>where <i>x</i> and <i>y</i> are input vectors, <i>c</i> is a constant (often set to 1), and <i>d</i> is the degree of the polynomial.\n",
        "\n",
        "This kernel function implicitly maps the inputs into a higher-dimensional space, allowing linear algorithms to find nonlinear patterns in the data.</p>\n",
        "\n",
        "We demonstrate the power for the almost trivial case of d = 1, c = 0 in code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zH58cSOZ40O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate sample data\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = np.linspace(-10, 10, 100)\n",
        "X, Y = np.meshgrid(x,y)\n",
        "Z = X*Y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "plt.contourf(X, Y, Z)\n",
        "plt.title('Linear Kernel Visualization')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u1A2HPAJEvMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcucA9l3dWli"
      },
      "source": [
        "## Kernel comparison (Exercise)\n",
        "Idea: There are many different types of kernels, and often we have to find the best one for our specific dataset.\n",
        "\n",
        "Task: Check the documentation of sklearn and evaluate kernels visually using the dataset and visualization tools prepared below.\n",
        "\n",
        "Bonus question: How could we benchmark the kernels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRIgwyZbcjHd"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn import svm\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
        "                           random_state=1, n_clusters_per_class=1)\n",
        "rng = np.random.RandomState(2)\n",
        "X += 2 * rng.uniform(size=X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_svm(kernel):\n",
        "    clf = svm.SVC(kernel=kernel, gamma='auto')\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "    plot_svc_decision_function(clf)\n",
        "    plt.title('SVM with ' + kernel + ' kernel')\n",
        "    plt.show()\n",
        "\n",
        "def plot_svc_decision_function(clf):\n",
        "    ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # create grid to evaluate model\n",
        "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
        "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
        "    YY, XX = np.meshgrid(yy, xx)\n",
        "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "    Z = clf.decision_function(xy).reshape(XX.shape)\n",
        "\n",
        "    # plot decision boundary and margins\n",
        "    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
        "               linestyles=['--', '-', '--'])\n",
        "    # plot support vectors\n",
        "    assert len(clf.support_vectors_) > 0, \"No support vectors found!\"\n",
        "    ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
        "               facecolors='none', edgecolors='k', marker='o')\n",
        "    return\n"
      ],
      "metadata": {
        "id": "JsPdewfzF04W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo: Try the different kernels from sklearn.\n",
        "plot_svm(kernel=\"linear\")"
      ],
      "metadata": {
        "id": "Evku-TzAF29b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantitative comparison\n",
        "Benchmarks the kernels by completing the following steps."
      ],
      "metadata": {
        "id": "VkV4fHwAcbeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_generalization_accuracy(\n",
        "    training_gram, training_labels, testing_gram, testing_labels\n",
        "):\n",
        "    \"\"\"\n",
        "    Calculate accuracy w.r.t. a precomputed kernel, a training and testing set\n",
        "\n",
        "    Args:\n",
        "        training_gram: Gram matrix of the training set, must have shape (N,N)\n",
        "        training_labels: Labels of the training set, must have shape (N,)\n",
        "        testing_gram: Gram matrix of the testing set, must have shape (M,N)\n",
        "        testing_labels: Labels of the training set, must have shape (M,)\n",
        "\n",
        "    Returns:\n",
        "        generalization accuracy (float)\n",
        "    \"\"\"\n",
        "    svm = SVC(kernel=\"precomputed\")\n",
        "    svm.fit(training_gram, training_labels)\n",
        "    y_predict = svm.predict(testing_gram)\n",
        "    correct = np.sum(testing_labels == y_predict)\n",
        "    accuracy = correct / len(testing_labels)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "uyXM1HzkcoIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import linear_kernel, rbf_kernel, polynomial_kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Todo: Perform a train test split.\n",
        "# Hint: Use X and y generated before.\n",
        "# X_train, X_test, y_train, y_test =\n",
        "\n",
        "# Compute the linear kernel\n",
        "lin_ker_tr = linear_kernel(X_train)\n",
        "lin_ker_te = linear_kernel(X_test, X_train)\n",
        "\n",
        "# Todo: Do the same for the rbf and polynomial kernel\n",
        "# rbf_ker_tr =\n",
        "# rbf_ker_te =\n",
        "# poly_ker_tr =\n",
        "# poly_ker_te =\n",
        "\n",
        "# Evaluate the accuracy\n",
        "lin_acc = calculate_generalization_accuracy(lin_ker_tr, y_train, lin_ker_te, y_test)\n",
        "# rbf_acc =\n",
        "# poly_acc =\n",
        "\n",
        "# Print the result\n",
        "print(f\"linear: {lin_acc}\")\n",
        "# print(f\"rbf: {rbf_acc}\")\n",
        "# print(f\"poly: {poly_acc}\")"
      ],
      "metadata": {
        "id": "c8iuPObZaP-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tolxARYndq8b"
      },
      "source": [
        "## Non-linear data separation: RBF Kernel\n",
        "<p>Another powerful kernel used in machine learning is the Radial Basis Function (RBF) kernel, also known as the Gaussian kernel:</p>\n",
        "<p><i>K(x, y)</i> = exp(<sup><i>-||x - y||</i><sup>2</sup></sup> / (2<i>σ</i><sup>2</sup>))</p>\n",
        "<p>where <i>σ</i> is the width of the Gaussian function. The RBF kernel is particularly useful as it can project data into an infinite-dimensional space, often making it linearly separable.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk_evmBfcq0B"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
        "\n",
        "def plot_dataset(X, y, axes):\n",
        "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
        "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
        "    plt.axis(axes)\n",
        "    plt.grid(True, which='both')\n",
        "\n",
        "def plot_predictions(clf, axes):\n",
        "    x0s = np.linspace(axes[0], axes[1], 100)\n",
        "    x1s = np.linspace(axes[2], axes[3], 100)\n",
        "    x0, x1 = np.meshgrid(x0s, x1s)\n",
        "    X = np.c_[x0.ravel(), x1.ravel()]\n",
        "    y_pred = clf.predict(X).reshape(x0.shape)\n",
        "    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n",
        "\n",
        "clf = svm.SVC(kernel='rbf', gamma='auto')\n",
        "clf.fit(X, y)\n",
        "plot_predictions(clf, [-1.5, 2.5, -1, 1.5])\n",
        "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ6vJ4m4syvp"
      },
      "source": [
        "## Quantum Kernels in Qiskit\n",
        "In this example, we'll encode the classical data point x=(−0.1,0.2) using the ZZFeatureMap in Qiskit."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installations\n",
        "!pip install qiskit\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "y-0ekP_VGb8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.circuit.library import ZZFeatureMap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the classical data.\n",
        "x = [-0.15, 0.28]\n",
        "\n",
        "# Setup the feature map and encode the data.\n",
        "feature_map = ZZFeatureMap(feature_dimension=len(x), reps=1, insert_barriers=True)\n",
        "encoded_data = feature_map.bind_parameters(x)"
      ],
      "metadata": {
        "id": "J0b_tvatK8yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the quantum circuit\n",
        "print(encoded_data.decompose().draw('text'))"
      ],
      "metadata": {
        "id": "dNz3XbONKXGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature maps (Exercise)\n",
        "\n",
        "\n",
        "**1. Explore Different Feature Maps:**\n",
        "\n",
        "Using the ZFeatureMap and PauliFeatureMap classes in Qiskit, create quantum circuits that encode the same data point x as used in the example above. Compare the circuits with the one generated using ZZFeatureMap.\n",
        "\n",
        "**2. Change Repetitions:**\n",
        "\n",
        "Modify the number of repetitions (reps) in the ZZFeatureMap from the example. How does the circuit change? What effect might this have on encoding?\n",
        "Encode Different Data Points: Choose two new data points and encode them using the ZZFeatureMap.\n",
        "\n",
        "**3. Compare the resulting circuits:**\n",
        "\n",
        "How does the circuit change with different data?\n",
        "\n",
        "\n",
        "**Hints**\n",
        "\n",
        "* For the ZFeatureMap, you may use the code ZFeatureMap(feature_dimension=len(x), reps=2) to create the map.\n",
        "\n",
        "* For the PauliFeatureMap, you may use the code PauliFeatureMap(feature_dimension=len(x), reps=2, paulis=['Z', 'X']) to create the map.\n",
        "\n",
        "* Remember to use bind_parameters to bind the data to the circuit, and print the circuit using print(circuit.decompose().draw('text')).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6QnmNCZZIhmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantum Kernels (Example)\n",
        "We already saw quantum feature maps in action. Here is an example of the simulation of a quantum kernel value for two data points with the ZZFeatureMap."
      ],
      "metadata": {
        "id": "KCF2bq2WL_Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.circuit.library import ZZFeatureMap\n",
        "from qiskit.quantum_info import Statevector\n",
        "\n",
        "# Define the classical data.\n",
        "x_i = [-0.15, 0.28]\n",
        "\n",
        "# Todo: Try x_j = [-0.15, 0.28] as sanity check. To you get the expected result?\n",
        "x_j = [0.12, -0.07]\n",
        "\n",
        "# Setup the feature map.\n",
        "feature_map = ZZFeatureMap(feature_dimension=len(x_i), reps=1)\n",
        "\n",
        "# Encode the data.\n",
        "encoded_x_i = feature_map.bind_parameters(x_i)\n",
        "encoded_x_j = feature_map.bind_parameters(x_j)\n",
        "\n",
        "# Get the statevector for both data points.\n",
        "statevector_i = Statevector.from_instruction(encoded_x_i)\n",
        "statevector_j = Statevector.from_instruction(encoded_x_j)\n",
        "\n",
        "# Calculate the quantum kernel.\n",
        "kernel_value = abs(statevector_j.conjugate().data @ statevector_i.data)**2\n",
        "print(\"Quantum Kernel Value:\", kernel_value)"
      ],
      "metadata": {
        "id": "b6QOC6CALb4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Support Vector Machine with a Quantum Kernel (Exercise)\n",
        "In this exercise, you will build a simple support vector machine (SVM) using the quantum kernel calculated from two data points from before. You will use the ZZFeatureMap for encoding the data.\n",
        "\n",
        "**Your tasks:**\n",
        "\n",
        "* Implement a function quantum_kernel that takes two data points as input and returns the kernel value using the method provided above.\n",
        "* Build a support vector machine using the calculated quantum kernel for the two given data points with labels y_i = 1 and y_j = -1.\n",
        "* Train the SVM on these data points and test the prediction.\n",
        "\n",
        "**Hint**\n",
        "\n",
        "You can use any SVM library that allows custom kernels. For instance, you can use the SVC class from scikit-learn with the precomputed kernel option."
      ],
      "metadata": {
        "id": "haBxNkpoZvPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.circuit.library import ZZFeatureMap\n",
        "from qiskit.quantum_info import Statevector\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# Todo: Implement.\n",
        "def quantum_kernel(x1, x2):\n",
        "    pass\n",
        "\n",
        "# Data points and labels\n",
        "X = np.array([[-0.15, 0.28], [0.12, -0.07]])\n",
        "y = np.array([1, -1])\n",
        "\n",
        "# Compute the kernel matrix\n",
        "K = np.array([[quantum_kernel(X[i], X[j]) for j in range(len(X))] for i in range(len(X))])\n",
        "\n",
        "# Train the SVM\n",
        "qsvm = SVC(kernel='precomputed')\n",
        "qsvm.fit(K, y)\n",
        "\n",
        "# Predict\n",
        "predictions = qsvm.predict(K)\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "id": "1Isj4SaUZqC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sources\n",
        "This tutorial is based on contents from the following sources:\n",
        "\n",
        "\n",
        "* Qiskit tutorials ([Kernel tutorial](https://qiskit.org/ecosystem/machine-learning/tutorials/03_quantum_kernel.html))\n",
        "* Qiskit labs ([Website](https://qiskit.org/textbook/ch-labs/))\n",
        "* Presentations ([Images](https://bmsce.ac.in/Content/CS/Linearly_separable_1.pdf))\n",
        "* Papers ([QuASK](https://arxiv.org/abs/2206.15284))\n",
        "* Textbooks ([Mike and Ike](https://www.cambridge.org/highereducation/books/quantum-computation-and-quantum-information/01E10196D0A682A6AEFFEA52D53BE9AE#overview))\n"
      ],
      "metadata": {
        "id": "92fKDUHN97HN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus material\n",
        "For everyone interested in learning more about quantum computing and software engineering best practices, we share our favorite material.\n",
        "\n",
        "* Quantum Advantage Seeker for Kernels (Resarch at CERN)\n",
        "* Best Practices in Software Engineering (Lived at CERN)\n",
        "* Examples, Exercises and Tutorials\n",
        "\n"
      ],
      "metadata": {
        "id": "Ng_A7PHFAKMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantum Kernels with QuASK\n",
        "An introduction to the Quantum Advantage Seeker for Kernels (QuASK) developed at CERN. QuASK facilitates the creation of quantum kernels and tackles many of the time-consuming and error-prone aspects of QML experimentation."
      ],
      "metadata": {
        "id": "ezp4yGXx_6kY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general pipeline of QuASK works as follows\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WMFyMj7In99dvGRSKFebJHBxK3E7zoJN\" width=\"1400\" height=\"90\" />\n",
        "\n"
      ],
      "metadata": {
        "id": "xtYCghoO78we"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Retrieval\n",
        "QuASK provides several datasets that can be retrieved using the get-dataset command. This command fetches one of the datasets available in quask.datasets module. The command produces two NumPy binary files representing the feature data and the corresponding labels of the chosen dataset."
      ],
      "metadata": {
        "id": "83CHZrNi6kjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1WwBOQ2NMVvL8avfK5O1m31_hLWVHnwXd\" width=\"900\" height=\"300\" />"
      ],
      "metadata": {
        "id": "2NxoY46A-0xc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Preprocessing\n",
        "Once a dataset is retrieved, preprocessing can be performed on it. Preprocessing can include dimensionality reduction, fixing imbalances in the classes using random undersampling or oversampling, and more. This is especially important in the Noisy Intermediate-Scale Quantum (NISQ) setting due to the lack of resources."
      ],
      "metadata": {
        "id": "Fc8stwbU7FaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1J5tq8uW-e8zBfBb95SOpgINU_XWVg82Q\" width=\"900\" height=\"400\" />\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QaFSMATHDxnx4naD20ghfpfHeq4iIszp\" width=\"900\" height=\"350\" />\n"
      ],
      "metadata": {
        "id": "wP7MrKZT_rl4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will retrieve the Iris dataset, and then preprocess it. The --output-folder argument specifies the output directory, and the --classical-feature-data-path and --classical-feature-data-path-labels arguments specify the paths to the feature data and labels, respectively."
      ],
      "metadata": {
        "id": "wy3phT948Ifu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the Processed Dataset\n",
        "Once preprocessing is completed, four .npy files are generated, namely X_train.npy, y_train.npy, X_test.npy, and y_test.npy. These represent the training feature data, training labels, testing feature data, and testing labels, respectively.\n",
        "\n",
        "We can load and inspect these datasets using numpy."
      ],
      "metadata": {
        "id": "4YvYkLjz8cD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Kernels\n",
        "In the context of QuASK, kernels are functions used in the quantum machine learning pipeline. QuASK supports both fixed and trainable kernels.\n",
        "\n",
        "**Fixed Kernels**\n",
        "\n",
        "Fixed kernels are pre-defined kernel functions such as linear, radial basis function (RBF), or polynomial kernels, as well as some quantum kernels. Here's an example of how you might apply a fixed kernel (in this case, a linear kernel):\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FnS5H3E_h6gQn2I1Q5y9YS2RnF1ThrIu\" width=\"900\" height=\"400\" />"
      ],
      "metadata": {
        "id": "AQWOD5f1MKXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This command applies a fixed linear kernel (specified by --kernel 0) to the datasets."
      ],
      "metadata": {
        "id": "Od5j1gg0MTct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trainable Kernels**\n",
        "\n",
        "Trainable kernels are parametric quantum circuits that depend on both the input data and some trainable parameters. These parameters are typically trained with gradient-descent-based optimization algorithms."
      ],
      "metadata": {
        "id": "Y_EmOHVEMXB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Metrics and Comparing Kernels\n",
        "QuASK provides the 'plot-metric' command to analyze and visualize the performance of different kernels. This feature allows you to compare different kernels and their performances on the given dataset.\n",
        "\n",
        "The 'plot-metric' command takes the Gram matrices of the training and testing sets, along with the corresponding labels, and a user-specified metric to calculate. It generates a plot where the kernels are compared in terms of the chosen metric."
      ],
      "metadata": {
        "id": "nNhNZ0sTM0wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1siMzfjlID8PhRq90kSXhReLCxaeDVLnc\" width=\"900\" height=\"400\" />"
      ],
      "metadata": {
        "id": "_1VUeEsF_WAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customizing Kernels and Feature Maps (Exercise)\n",
        "\n",
        "QuASK allows advanced users to create custom kernels and feature maps. While this goes beyond the scope of this tutorial, here's a brief idea of how you might proceed:\n",
        "\n",
        "Define a new Python function implementing your custom kernel or feature map.\n",
        "Register your custom function in the QuASK kernel register.\n",
        "You can now use your custom function just like any of the predefined ones.\n",
        "Please refer to the QuASK documentation and source code for more details on how to implement and use custom kernels and feature maps."
      ],
      "metadata": {
        "id": "WIsBGKFPNGxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion and Further Exploration\n",
        "With this tutorial, you have been introduced to the Quantum Advantage Seeker with Kernels (QuASK) and its main features. You've learned how to retrieve and preprocess datasets, apply fixed and trainable kernels, and compare the performance of different kernels using QuASK.\n",
        "\n",
        "Remember that while this tutorial provides a starting point, the real power of QuASK comes from its flexibility and extensibility. You're encouraged to explore different datasets, try out different kernels, create your own custom kernels and feature maps, and generally experiment to find the best solutions for your quantum machine learning tasks.\n",
        "\n",
        "Happy quantum computing!"
      ],
      "metadata": {
        "id": "qBdt_Rm8NREp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Software Engineering"
      ],
      "metadata": {
        "id": "VwiN9W1OBEJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Investing in software engineering best practices is important. Here are ten"
      ],
      "metadata": {
        "id": "hmi_rXRbNYxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Git: Use Git for version control to keep track of code changes, making collaboration and code sharing easy. Learn more [here](https://learngitbranching.js.org/)\n",
        "\n",
        "* Unit Testing: Write tests for your code to ensure its robustness and confidence in refactoring. Learn more [here](https://realpython.com/pytest-python-testing/)\n",
        "\n",
        "* Virtual Environments: Use virtual environments for reproducible setups and easy installations. Learn more [here](https://www.dataquest.io/blog/a-complete-guide-to-python-virtual-environments/)\n",
        "\n",
        "* Clean Code: Follow clean code principles for readable, maintainable and robust software. Learn more here\n",
        "\n",
        "* Design Patterns: Leverage established design patterns to solve common problems in software design. Learn more here\n",
        "\n",
        "* Packaging in Python: Package your Python code into libraries for easy distribution and installation. Learn more [here](https://packaging.python.org/en/latest/tutorials/packaging-projects/)\n",
        "\n",
        "* Data Structures and Algorithms: Mastering fundamental data structures and algorithms often provides more value than learning trendy frameworks. Learn more [here](https://www.geeksforgeeks.org/introduction-to-data-structures/)\n",
        "\n",
        "* Autodocs with Sphinx: Use Sphinx to automatically generate documentation from your code. Learn more [here](https://eikonomega.medium.com/getting-started-with-sphinx-autodoc-part-1-2cebbbca5365)\n",
        "\n",
        "* Cloud Computing: Develop and run your code on cloud platforms for scalable workflows. Checkout AWS!\n",
        "\n",
        "* Containers: Use containers to encapsulate your code into standalone, reproducible units of software. Checkout Docker!\n",
        "\n",
        "* Container Orchestration: Use container orchestration tools to manage and scale your applications. Checkout Kubernetes!"
      ],
      "metadata": {
        "id": "9egYgWr6OEgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantum Computing\n",
        "\n",
        "Checkout our favorite tutorials by IBM.\n",
        "\n",
        "* [Quantum Neural Networks](https://qiskit.org/ecosystem/machine-learning/tutorials/01_neural_networks.html)\n",
        "* [Quantum Kernels Tutorial](https://qiskit.org/ecosystem/machine-learning/tutorials/03_quantum_kernel.html)\n",
        "* [Quantum Noise](https://www.tensorflow.org/quantum/tutorials/noise)"
      ],
      "metadata": {
        "id": "N8f6lVlUBAaG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu9ZK60ErzIs"
      },
      "source": [
        "## Hyperparameters tuning (Example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYDoFFeLqo75"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_circles(n_samples=1000, noise=0.05)\n",
        "\n",
        "# Grid Search\n",
        "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01]}\n",
        "grid = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, refit=True, verbose=2)\n",
        "grid.fit(X, y)\n",
        "\n",
        "# SVM with best parameters\n",
        "clf = svm.SVC(kernel='rbf', C=grid.best_params_['C'], gamma=grid.best_params_['gamma'])\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Plotting\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap='autumn')\n",
        "plot_svc_decision_function(clf)\n",
        "plt.title('SVM with tuned parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernel Principal Component Analysis (Example)"
      ],
      "metadata": {
        "id": "Np9QFqE5Mhsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjbbiO-hqPRO"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_circles(n_samples=400, factor=.3, noise=.05)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "\n",
        "# Plot synthetic data\n",
        "plt.title(\"Raw data\")\n",
        "plt.show()\n",
        "\n",
        "# Kernel PCA\n",
        "kpca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=10)\n",
        "X_kpca = kpca.fit_transform(X)\n",
        "\n",
        "# Plotting\n",
        "plt.scatter(X_kpca[:, 0], X_kpca[:, 1], c=y)\n",
        "plt.title(\"Kernel PCA\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5YQi8ffqDW8"
      },
      "source": [
        "## SVM with custom kernel (Exercise)\n",
        "A fun part about kernels is that you can also implement your own version.\n",
        "Task: Checkout the plot of the data below and implement your own kernel to separate the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AqIXVQadvtZ"
      },
      "outputs": [],
      "source": [
        "# Todo: Implement your own kernel\n",
        "def custom_kernel(X, Y):\n",
        "    return np.dot(X, Y.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSLzl_bHqMHY"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "from sklearn import svm\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_circles(n_samples=100, factor=.3, noise=.05)\n",
        "\n",
        "# SVM classifier with custom kernel\n",
        "clf = svm.SVC(kernel=custom_kernel)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Plotting\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap='autumn')\n",
        "\n",
        "# Todo: Implement your own kernel such that support vectors are found.\n",
        "# plot_svc_decision_function(clf)\n",
        "plt.title('SVM with custom kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hint: The script gives us error because our simple custom kernel does not find any correct separating hyperplane. Hence, no support vectors found!"
      ],
      "metadata": {
        "id": "7NHfy9Ztn9Bd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}